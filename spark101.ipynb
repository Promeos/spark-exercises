{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Fundamentals Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.functions import col, exp, lit, concat, regexp_extract, regexp_replace, expr\n",
    "from pyspark.sql.functions import round, sum, avg, min, max, count, mean\n",
    "from pyspark.sql.functions import udf, year, month, quarter, asc, desc\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from pydataset import data\n",
    "from vega_datasets import data as vega_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark instance/session\n",
    "\n",
    "spark = pyspark.sql.SparkSession.Builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "    The name of the column should be language\n",
    "    View the schema of the dataframe\n",
    "    Output the shape of the dataframe\n",
    "    Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas dataframe object with a column named language.\n",
    "df_langs = pd.DataFrame({'language':['Spark', 'Pandas', 'Numpy',\n",
    "                                     'Python', 'PyTorch', 'Qiskit']})\n",
    "\n",
    "# Pass the pandas dataframe as an argument to create a spark dataframe.\n",
    "df = spark.createDataFrame(df_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- language: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# View the schema of the programming language dataframe.\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# View the shape of the Spark dataframe.\n",
    "df.count(), len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+\n|language|\n+--------+\n|   Spark|\n|  Pandas|\n|   Numpy|\n|  Python|\n| PyTorch|\n+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# View the top 5 rows of the pandas dataframe.\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Row(language='Spark')]\n[Row(language='Spark')]\n"
     ]
    }
   ],
   "source": [
    "# Returns the first element from the column named 'language'\n",
    "print(df.limit(1).collect())\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+--------+\n|summary|language|\n+-------+--------+\n|  count|       6|\n|   mean|    null|\n| stddev|    null|\n|    min|   Numpy|\n|    25%|    null|\n|    50%|    null|\n|    75%|    null|\n|    max|   Spark|\n+-------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  language\n",
       "0    Spark\n",
       "1   Pandas\n",
       "2    Numpy\n",
       "3   Python\n",
       "4  PyTorch\n",
       "5   Qiskit"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Spark</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pandas</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Numpy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Python</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PyTorch</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Qiskit</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "    Create 1 column of output that contains a message like the one below:\n",
    "\n",
    "    The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "    Transform the `trans` column so it only contains 'manual' or 'auto'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark dataframe using a pandas dataframe\n",
    "# Data source is pydataset --- 'mpg'\n",
    "mpg = spark.createDataFrame(data('mpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n+------------+-----+-----+----+---+----------+---+---+---+---+-------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Look at the first few rows to understand which columns hold\n",
    "# the information we need to make a descriptive sentence column.\n",
    "\n",
    "mpg.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named `vehicle_summary` to store\n",
    "# the summary of each vehicle.\n",
    "\n",
    "# The .withColumn() function creates a new column\n",
    "# for spark dataframes- similar to pandas .assign()\n",
    "mpg = (\n",
    "mpg.withColumn(colName='vehicle_summary',\n",
    "               col=concat(lit('The '), # Strings that are not values in the spark dataframe need to be called with the lit() function\n",
    "                          'year',  # Column names in a spark dataframe can be referenced by name. The function is called directly on the spark dataframe\n",
    "                          lit(' '),\n",
    "                          'manufacturer',\n",
    "                          lit(' '),\n",
    "                          'model',\n",
    "                          lit(' has a '),\n",
    "                          'cyl',\n",
    "                          lit(' cylinder engine.'))\n",
    "              )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------------------------------+\n|vehicle_summary                          |\n+-----------------------------------------+\n|The 1999 audi a4 has a 4 cylinder engine.|\n|The 1999 audi a4 has a 4 cylinder engine.|\n|The 2008 audi a4 has a 4 cylinder engine.|\n|The 2008 audi a4 has a 4 cylinder engine.|\n|The 1999 audi a4 has a 6 cylinder engine.|\n+-----------------------------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# To display all the text in a column, we need to set truncate=False in .show()\n",
    "# Truncate will truncate all strings longer than 20 characters by default.\n",
    "mpg.select('vehicle_summary').show(n=5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+------------+\n|     trans|transmission|\n+----------+------------+\n|  auto(l5)|        auto|\n|manual(m5)|      manual|\n|manual(m6)|      manual|\n|  auto(av)|        auto|\n|  auto(l5)|        auto|\n|manual(m5)|      manual|\n|  auto(av)|        auto|\n|manual(m5)|      manual|\n|  auto(l5)|        auto|\n|manual(m6)|      manual|\n|  auto(s6)|        auto|\n|  auto(l5)|        auto|\n|manual(m5)|      manual|\n|  auto(s6)|        auto|\n|manual(m6)|      manual|\n|  auto(l5)|        auto|\n|  auto(s6)|        auto|\n|  auto(s6)|        auto|\n|  auto(l4)|        auto|\n|  auto(l4)|        auto|\n+----------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Transform the trans column so that it only contains either manual or auto.\n",
    "# Use the `.select()` function to grab the transmission column.\n",
    "\n",
    "# I include the 'trans' column to compare the transformed column with the original.\n",
    "mpg.select('trans',\n",
    "           regexp_extract('trans', '(\\w+)', 1).alias('transmission')\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `regexp_function()` to extract the transmission class: auto and manual\n",
    "# from the `trans` column.\n",
    "\n",
    "mpg = mpg.withColumn(colName='transmission',\n",
    "                     col=regexp_extract('trans', '(\\w+)', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+------------+\n|     trans|transmission|\n+----------+------------+\n|  auto(l5)|        auto|\n|manual(m5)|      manual|\n|manual(m6)|      manual|\n+----------+------------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "mpg.select('trans', 'transmission').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load the tips dataset as a spark dataframe.\n",
    "\n",
    "    What percentage of observations are smokers?\n",
    "    Create a column that contains the tip percentage\n",
    "    Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tips dataset from pydataset and pass the returned\n",
    "# Dataframe into a spark dataframe\n",
    "tips = spark.createDataFrame(data('tips'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(244, 7)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "tips.count(), len(tips.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- total_bill: double (nullable = true)\n |-- tip: double (nullable = true)\n |-- sex: string (nullable = true)\n |-- smoker: string (nullable = true)\n |-- day: string (nullable = true)\n |-- time: string (nullable = true)\n |-- size: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Display information about the column dtypes\n",
    "tips.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+----+------+------+---+------+----+\n|total_bill| tip|   sex|smoker|day|  time|size|\n+----------+----+------+------+---+------+----+\n|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n+----------+----+------+------+---+------+----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows to understand what a single observation represents\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+------------------+------------------+------+------+----+------+------------------+\n|summary|        total_bill|               tip|   sex|smoker| day|  time|              size|\n+-------+------------------+------------------+------+------+----+------+------------------+\n|  count|               244|               244|   244|   244| 244|   244|               244|\n|   mean|19.785942622950813|  2.99827868852459|  null|  null|null|  null| 2.569672131147541|\n| stddev| 8.902411954856856|1.3836381890011817|  null|  null|null|  null|0.9510998047322345|\n|    min|              3.07|               1.0|Female|    No| Fri|Dinner|                 1|\n|    max|             50.81|              10.0|  Male|   Yes|Thur| Lunch|                 6|\n+-------+------------------+------------------+------+------+----+------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Display descriptive statistics for each column.\n",
    "tips.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+---------------+\n|customers_who_smoke|total_customers|\n+-------------------+---------------+\n|                 93|            244|\n+-------------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "# number of smokers\n",
    "tips.select(sum((tips.smoker == 'Yes').cast('int')).alias('customers_who_smoke'),\n",
    "            count(tips.smoker).alias('total_customers')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percentage of customers who smoke\n+-------------------+\n|     pct_of_smokers|\n+-------------------+\n|0.38114754098360654|\n+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# What percentage of observations are smokers?\n",
    "\n",
    "# To calcaulte the percentage of smokers, the output of\n",
    "# the boolean expression  must be cast into an integer.\n",
    "print(\"Percentage of customers who smoke\")\n",
    "tips.select(\n",
    "    avg((col('smoker') == 'Yes').cast('int'))\n",
    "    .alias('pct_of_smokers')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the withColumn function to create a new column using\n",
    "# existing columns from the tips spark dataframe\n",
    "\n",
    "tips = tips.withColumn(colName='tip_pct',\n",
    "                       col=(col('tip') / col('total_bill'))\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n+----------+----+------+------+---+------+----+-------------------+\n|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n+----------+----+------+------+---+------+----+-------------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "tips.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+------+-----------+\n|   sex|smoker|avg_tip_pct|\n+------+------+-----------+\n|  Male|    No|      0.161|\n|  Male|   Yes|      0.153|\n|Female|    No|      0.157|\n|Female|   Yes|      0.182|\n+------+------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average tip percentage for each combination of sex and smoker\n",
    "\n",
    "tips.groupBy('sex', 'smoker').agg(round(avg('tip_pct'),3).alias('avg_tip_pct')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "    Convert the temperatures to farenheight.\n",
    "    Which month has the most rain, on average?\n",
    "    Which year was the windiest?\n",
    "    What is the most frequent type of weather in January?\n",
    "    What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "    What percentage of days were rainy in q3 of 2015?\n",
    "    For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = vega_data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "weather = spark.createDataFrame(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1461, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "weather.count(), len(weather.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- date: string (nullable = true)\n |-- precipitation: double (nullable = true)\n |-- temp_max: double (nullable = true)\n |-- temp_min: double (nullable = true)\n |-- wind: double (nullable = true)\n |-- weather: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "weather.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n|      date|precipitation|temp_max|temp_min|wind|weather|\n+----------+-------------+--------+--------+----+-------+\n|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n+----------+-------------+--------+--------+----+-------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "weather.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+----------+-----------------+------------------+-----------------+------------------+-------+\n|summary|      date|    precipitation|          temp_max|         temp_min|              wind|weather|\n+-------+----------+-----------------+------------------+-----------------+------------------+-------+\n|  count|      1461|             1461|              1461|             1461|              1461|   1461|\n|   mean|      null| 3.02943189596167|16.439082819986307|8.234770704996578|3.2411362080766595|   null|\n| stddev|      null|6.680194322314738| 7.349758097360178|5.023004179961266|1.4378250588746198|   null|\n|    min|2012-01-01|              0.0|              -1.6|             -7.1|               0.4|drizzle|\n|    max|2015-12-31|             55.9|              35.6|             18.3|               9.5|    sun|\n+-------+----------+-----------------+------------------+-----------------+------------------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "weather.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n|      date|precipitation|temp_max|temp_min|wind|weather|\n+----------+-------------+--------+--------+----+-------+\n|2012-01-01|          0.0|   55.04|    41.0| 4.7|drizzle|\n|2012-01-02|         10.9|   51.08|   37.04| 4.5|   rain|\n|2012-01-03|          0.8|   53.06|   44.96| 2.3|   rain|\n|2012-01-04|         20.3|   53.96|   42.08| 4.7|   rain|\n|2012-01-05|          1.3|   48.02|   37.04| 6.1|   rain|\n+----------+-------------+--------+--------+----+-------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#C onvert the temperatures to farenheit.\n",
    "# C = 5/9 x (F-32)\n",
    "\n",
    "# Create a user defined function from pyspark.sql.functions.udf\n",
    "# that will convert temperatures from Celsius to Fahrenheit.\n",
    "udf_temp_conversion = udf(lambda temp: temp * (9/5) + 32, FloatType())\n",
    "\n",
    "# Transform the max temperature from Celsius to Fahrenheit\n",
    "weather = weather.withColumn(colName='temp_max',\n",
    "                             col=udf_temp_conversion(col('temp_max')))\n",
    "\n",
    "# Transform the min temperature from Celsius to Fahrenheit\n",
    "weather = weather.withColumn(colName='temp_min',\n",
    "                             col=udf_temp_conversion(col('temp_min')))\n",
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+--------+\n|month|avg_rain|\n+-----+--------+\n|   10|   9.675|\n+-----+--------+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "# Which month has the most rain, on average?\n",
    "(\n",
    "weather\n",
    ".filter(col('weather') == lit('rain'))\n",
    ".groupBy(month('date').alias('month'))\n",
    ".agg(avg('precipitation').alias('avg_rain'))\n",
    ".sort(col('avg_rain').desc())\n",
    ".show(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----+------------------+\n|year|          avg_wind|\n+----+------------------+\n|2012|3.4008196721311483|\n+----+------------------+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "# Which year was the windiest?\n",
    "(\n",
    "weather\n",
    ".groupBy(year('date').alias('year'))\n",
    ".agg(avg('wind').alias('avg_wind'))\n",
    ".sort(col('avg_wind').desc())\n",
    ".show(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+-----+\n|weather|count|\n+-------+-----+\n|    fog|   38|\n+-------+-----+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "# What is the most frequent type of weather in January?\n",
    "(\n",
    "weather.filter(month('date') == 1)\n",
    ".groupBy('weather')\n",
    ".agg(count('weather').alias('count'))\n",
    ".sort(col('count').desc())\n",
    ".show(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----+-----------------+-----------------+\n|year|     avg_max_temp|     avg_min_temp|\n+----+-----------------+-----------------+\n|2013|79.85333421495226|57.16666652538158|\n|2014|80.76559967041015|            57.92|\n+----+-----------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "(\n",
    "weather\n",
    "    \n",
    "# Filter the dataset for sunny weather conditions\n",
    ".filter(col('weather') == 'sun')\n",
    "    \n",
    "# in 2013 and 2014\n",
    ".where(year('date').isin([2013, 2014]))\n",
    "\n",
    "# in July \n",
    ".where(month('date') == 7)\n",
    "\n",
    "# Group July weather data by year\n",
    ".groupBy(year('date').alias('year'))\n",
    "    \n",
    "# Calculate the average max and min temperatures\n",
    ".agg(avg('temp_max').alias('avg_max_temp'),\n",
    "     avg('temp_min').alias('avg_min_temp'))\n",
    "    \n",
    "# Display the results.\n",
    ".show()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n|   Q3_pct_days_rainy|\n+--------------------+\n|0.021739130434782608|\n+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# What percentage of days were rainy in q3 of 2015?\n",
    "(\n",
    "weather\n",
    "    \n",
    "# Filter 2015 temperature data\n",
    ".filter(year('date') == 2015)\n",
    "    \n",
    "# In Q3 of 2015\n",
    ".where(quarter('date') == 3)\n",
    "    \n",
    "# calculate the percentage of rain days\n",
    ".select(avg((col('weather') == 'rain')\n",
    "        .cast('int'))\n",
    "        .alias('Q3_pct_days_rainy'))\n",
    "\n",
    "# Display the results\n",
    ".show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----+-----------------+\n|year|avg_precipitation|\n+----+-----------------+\n|2015|            0.395|\n|2013|            0.416|\n|2014|            0.411|\n|2012|            0.484|\n+----+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# For each year, find what percentage of days it rained (had non-zero precipitation).\n",
    "\n",
    "(\n",
    "weather\n",
    "    \n",
    "# Select the years from the date column\n",
    ".select(year('date').alias('year'),\n",
    "\n",
    "# Create a Boolean series of non-zero precipitation days.\n",
    "(col('precipitation') != 0).cast('int').alias('precipitation'))\n",
    "    \n",
    "# Group by the year column\n",
    ".groupBy('year')\n",
    "    \n",
    "# Calculate the average number of days with percipitation for each year.\n",
    ".agg(round(mean('precipitation'), 3).alias('avg_precipitation'))\n",
    "    \n",
    "# Display the results.\n",
    ".show()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e134e05457d34029b6460cd73bbf1ed73f339b5b6d98c95be70b69eba114fe95"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}