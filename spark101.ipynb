{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Fundamentals Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.functions import col, exp, lit, concat, regexp_extract, regexp_replace, expr\n",
    "from pyspark.sql.functions import round, sum, avg, min, max, count, mean\n",
    "from pyspark.sql.functions import udf, year, month, quarter, asc, desc\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "from pydataset import data\n",
    "from vega_datasets import data as vega_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark instance/session\n",
    "\n",
    "spark = pyspark.sql.SparkSession.Builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "    The name of the column should be language\n",
    "    View the schema of the dataframe\n",
    "    Output the shape of the dataframe\n",
    "    Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas dataframe object with a column named language.\n",
    "df_langs = pd.DataFrame({'language':['Spark', 'Pandas', 'Numpy',\n",
    "                                     'Python', 'PyTorch', 'Qiskit']})\n",
    "\n",
    "# Pass the pandas dataframe as an argument to create a spark dataframe.\n",
    "df = spark.createDataFrame(df_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the schema of the programming language dataframe.\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the shape of the Spark dataframe.\n",
    "df.count(), len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|   Spark|\n",
      "|  Pandas|\n",
      "|   Numpy|\n",
      "|  Python|\n",
      "| PyTorch|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the top 5 rows of the pandas dataframe.\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(language='Spark')]\n",
      "[Row(language='Spark')]\n"
     ]
    }
   ],
   "source": [
    "# Returns the first element from the column named 'language'\n",
    "print(df.limit(1).collect())\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|summary|language|\n",
      "+-------+--------+\n",
      "|  count|       6|\n",
      "|   mean|    null|\n",
      "| stddev|    null|\n",
      "|    min|   Numpy|\n",
      "|    25%|    null|\n",
      "|    50%|    null|\n",
      "|    75%|    null|\n",
      "|    max|   Spark|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Numpy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PyTorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Qiskit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language\n",
       "0    Spark\n",
       "1   Pandas\n",
       "2    Numpy\n",
       "3   Python\n",
       "4  PyTorch\n",
       "5   Qiskit"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "    Create 1 column of output that contains a message like the one below:\n",
    "\n",
    "    The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "    Transform the `trans` column so it only contains 'manual' or 'auto'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark dataframe using a pandas dataframe\n",
    "# Data source is pydataset --- 'mpg'\n",
    "mpg = spark.createDataFrame(data('mpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at the first few rows to understand which columns hold\n",
    "# the information we need to make a descriptive sentence column.\n",
    "\n",
    "mpg.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named `vehicle_summary` to store\n",
    "# the summary of each vehicle.\n",
    "\n",
    "# The .withColumn() function creates a new column\n",
    "# for spark dataframes- similar to pandas .assign()\n",
    "mpg = (\n",
    "mpg.withColumn(colName='vehicle_summary',\n",
    "               col=concat(lit('The '), # Strings that are not values in the spark dataframe need to be called with the lit() function\n",
    "                          'year',  # Column names in a spark dataframe can be referenced by name. The function is called directly on the spark dataframe\n",
    "                          lit(' '),\n",
    "                          'manufacturer',\n",
    "                          lit(' '),\n",
    "                          'model',\n",
    "                          lit(' has a '),\n",
    "                          'cyl',\n",
    "                          lit(' cylinder engine.'))\n",
    "              )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+\n",
      "|vehicle_summary                          |\n",
      "+-----------------------------------------+\n",
      "|The 1999 audi a4 has a 4 cylinder engine.|\n",
      "|The 1999 audi a4 has a 4 cylinder engine.|\n",
      "|The 2008 audi a4 has a 4 cylinder engine.|\n",
      "|The 2008 audi a4 has a 4 cylinder engine.|\n",
      "|The 1999 audi a4 has a 6 cylinder engine.|\n",
      "+-----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To display all the text in a column, we need to set truncate=False in .show()\n",
    "# Truncate will truncate all strings longer than 20 characters by default.\n",
    "mpg.select('vehicle_summary').show(n=5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|     trans|transmission|\n",
      "+----------+------------+\n",
      "|  auto(l5)|        auto|\n",
      "|manual(m5)|      manual|\n",
      "|manual(m6)|      manual|\n",
      "|  auto(av)|        auto|\n",
      "|  auto(l5)|        auto|\n",
      "|manual(m5)|      manual|\n",
      "|  auto(av)|        auto|\n",
      "|manual(m5)|      manual|\n",
      "|  auto(l5)|        auto|\n",
      "|manual(m6)|      manual|\n",
      "|  auto(s6)|        auto|\n",
      "|  auto(l5)|        auto|\n",
      "|manual(m5)|      manual|\n",
      "|  auto(s6)|        auto|\n",
      "|manual(m6)|      manual|\n",
      "|  auto(l5)|        auto|\n",
      "|  auto(s6)|        auto|\n",
      "|  auto(s6)|        auto|\n",
      "|  auto(l4)|        auto|\n",
      "|  auto(l4)|        auto|\n",
      "+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the trans column so that it only contains either manual or auto.\n",
    "# Use the `.select()` function to grab the transmission column.\n",
    "\n",
    "# I include the 'trans' column to compare the transformed column with the original.\n",
    "mpg.select('trans',\n",
    "           regexp_extract('trans', '(\\w+)', 1).alias('transmission')\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `regexp_function()` to extract the transmission class: auto and manual\n",
    "# from the `trans` column.\n",
    "\n",
    "mpg = mpg.withColumn(colName='transmission',\n",
    "                     col=regexp_extract('trans', '(\\w+)', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|     trans|transmission|\n",
      "+----------+------------+\n",
      "|  auto(l5)|        auto|\n",
      "|manual(m5)|      manual|\n",
      "|manual(m6)|      manual|\n",
      "+----------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select('trans', 'transmission').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load the tips dataset as a spark dataframe.\n",
    "\n",
    "    What percentage of observations are smokers?\n",
    "    Create a column that contains the tip percentage\n",
    "    Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tips dataset from pydataset and pass the returned\n",
    "# Dataframe into a spark dataframe\n",
    "tips = spark.createDataFrame(data('tips'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips.count(), len(tips.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- total_bill: double (nullable = true)\n",
      " |-- tip: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display information about the column dtypes\n",
    "tips.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows to understand what a single observation represents\n",
    "# Row == Paying Customer\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------+------+----+------+------------------+\n",
      "|summary|        total_bill|               tip|   sex|smoker| day|  time|              size|\n",
      "+-------+------------------+------------------+------+------+----+------+------------------+\n",
      "|  count|               244|               244|   244|   244| 244|   244|               244|\n",
      "|   mean|19.785942622950813|  2.99827868852459|  null|  null|null|  null| 2.569672131147541|\n",
      "| stddev| 8.902411954856856|1.3836381890011817|  null|  null|null|  null|0.9510998047322345|\n",
      "|    min|              3.07|               1.0|Female|    No| Fri|Dinner|                 1|\n",
      "|    max|             50.81|              10.0|  Male|   Yes|Thur| Lunch|                 6|\n",
      "+-------+------------------+------------------+------+------+----+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display descriptive statistics for each column.\n",
    "tips.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "|num_smokers|total_customers|\n",
      "+-----------+---------------+\n",
      "|         93|            244|\n",
      "+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of smokers\n",
    "tips.select(sum((tips.smoker == 'Yes').cast('int')).alias('num_smokers'),\n",
    "            count(tips.smoker).alias('total_customers')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of customers who smoke\n",
      "+--------------+\n",
      "|pct_of_smokers|\n",
      "+--------------+\n",
      "|          0.38|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What percentage of observations are smokers?\n",
    "\n",
    "# To calcaulte the percentage of smokers, the output of\n",
    "# the boolean expression  must be cast into an integer.\n",
    "print(\"Percentage of customers who smoke\")\n",
    "tips.select(\n",
    "    round(avg((col('smoker') == 'Yes').cast('int')), 2)\n",
    "    .alias('pct_of_smokers')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the withColumn function to create a new column using\n",
    "# existing columns from the tips spark dataframe\n",
    "\n",
    "tips = tips.withColumn(colName='tip_pct',\n",
    "                       col=round(col('tip') / col('total_bill'), 4)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2| 0.0594|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3| 0.1605|\n",
      "+----------+----+------+------+---+------+----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----------+\n",
      "|   sex|smoker|avg_tip_pct|\n",
      "+------+------+-----------+\n",
      "|Female|    No|     0.1569|\n",
      "|Female|   Yes|     0.1821|\n",
      "|  Male|    No|     0.1607|\n",
      "|  Male|   Yes|     0.1528|\n",
      "+------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average tip percentage for each combination of sex and smoker\n",
    "# Groupby sex and smoker columns, and calculate the average tip per customer group\n",
    "# Alias the calculation with an explicit name.\n",
    "tips.groupBy('sex', 'smoker').agg(round(avg('tip_pct'),4).alias('avg_tip_pct')).sort('sex').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "    Convert the temperatures to fahrenheit.\n",
    "    Which month has the most rain, on average?\n",
    "    Which year was the windiest?\n",
    "    What is the most frequent type of weather in January?\n",
    "    What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "    What percentage of days were rainy in q3 of 2015?\n",
    "    For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the seattle weather dataset to a variable.\n",
    "# Use .assign to change the type of the `date` column to a string.\n",
    "weather = vega_data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "\n",
    "# Create a spark dataframe from the weather dataframe.\n",
    "weather = spark.createDataFrame(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1461, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the shape of the spark dataframe.\n",
    "weather.count(), len(weather.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- precipitation: double (nullable = true)\n",
      " |-- temp_max: double (nullable = true)\n",
      " |-- temp_min: double (nullable = true)\n",
      " |-- wind: double (nullable = true)\n",
      " |-- weather: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the column types of the spark dataframe using .printSchema()\n",
    "weather.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the first 3 rows of the dataframe to understand what an observation represents.\n",
    "weather.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------------+------------------+-----------------+------------------+-------+\n",
      "|summary|      date|    precipitation|          temp_max|         temp_min|              wind|weather|\n",
      "+-------+----------+-----------------+------------------+-----------------+------------------+-------+\n",
      "|  count|      1461|             1461|              1461|             1461|              1461|   1461|\n",
      "|   mean|      null| 3.02943189596167|16.439082819986307|8.234770704996578|3.2411362080766595|   null|\n",
      "| stddev|      null|6.680194322314738| 7.349758097360178|5.023004179961266|1.4378250588746198|   null|\n",
      "|    min|2012-01-01|              0.0|              -1.6|             -7.1|               0.4|drizzle|\n",
      "|    max|2015-12-31|             55.9|              35.6|             18.3|               9.5|    sun|\n",
      "+-------+----------+-----------------+------------------+-----------------+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display descriptive statistics of each column using .describe().show()\n",
    "weather.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|   55.04|    41.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|   51.08|   37.04| 4.5|   rain|\n",
      "|2012-01-03|          0.8|   53.06|   44.96| 2.3|   rain|\n",
      "|2012-01-04|         20.3|   53.96|   42.08| 4.7|   rain|\n",
      "|2012-01-05|          1.3|   48.02|   37.04| 6.1|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#C onvert the temperatures to farenheit.\n",
    "# C = 5/9 x (F-32)\n",
    "\n",
    "# Create a user defined function from pyspark.sql.functions.udf\n",
    "# that converts temperatures from Celsius to Fahrenheit.\n",
    "udf_temp_conversion = udf(lambda temp: temp * (9/5) + 32, FloatType())\n",
    "\n",
    "# Transform the max temperature from Celsius to Fahrenheit\n",
    "weather = weather.withColumn(colName='temp_max',\n",
    "                             col=udf_temp_conversion(col('temp_max')))\n",
    "\n",
    "# Transform the min temperature from Celsius to Fahrenheit\n",
    "weather = weather.withColumn(colName='temp_min',\n",
    "                             col=udf_temp_conversion(col('temp_min')))\n",
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "October has the most rain on average.\n",
      "+-----+--------+\n",
      "|month|avg_rain|\n",
      "+-----+--------+\n",
      "|   10|   9.675|\n",
      "+-----+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which month has the most rain, on average?\n",
    "print('October has the most rain on average.')\n",
    "(\n",
    "weather\n",
    ".filter(col('weather') == lit('rain'))\n",
    ".groupBy(month('date').alias('month'))\n",
    ".agg(avg('precipitation').alias('avg_rain'))\n",
    ".sort(col('avg_rain').desc())\n",
    ".show(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012 was the windiest year on average.\n",
      "+----+------------------+\n",
      "|year|          avg_wind|\n",
      "+----+------------------+\n",
      "|2012|3.4008196721311483|\n",
      "+----+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which year was the windiest?\n",
    "print(\"2012 was the windiest year on average.\")\n",
    "(\n",
    "weather\n",
    ".groupBy(year('date').alias('year'))\n",
    ".agg(avg('wind').alias('avg_wind'))\n",
    ".sort(col('avg_wind').desc())\n",
    ".show(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent type of weather in January is Fog.\n",
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|    fog|   38|\n",
      "+-------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the most frequent type of weather in January?\n",
    "print('The most frequent type of weather in January is Fog.')\n",
    "(\n",
    "weather.filter(month('date') == 1)\n",
    ".groupBy('weather')\n",
    ".agg(count('weather').alias('count'))\n",
    ".sort(col('count').desc())\n",
    ".show(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average high and lows for 2013 and 2014.\n",
      "+----+------------+------------+\n",
      "|year|avg_max_temp|avg_min_temp|\n",
      "+----+------------+------------+\n",
      "|2013|       79.85|       57.17|\n",
      "|2014|       80.77|       57.92|\n",
      "+----+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "print(\"The average high and lows for 2013 and 2014.\")\n",
    "(\n",
    "weather\n",
    "    \n",
    "# Filter the dataset for sunny weather conditions (.filter() is an alias for .where())\n",
    "# .filter(col('weather') == 'sun')\n",
    ".where(col('weather') == 'sun')\n",
    "    \n",
    "# in 2013 and 2014\n",
    ".where(year('date').isin([2013, 2014]))\n",
    "\n",
    "# in July \n",
    ".where(month('date') == 7)\n",
    "\n",
    "# Group July weather data by year\n",
    ".groupBy(year('date').alias('year'))\n",
    "    \n",
    "# Calculate the average max and min temperatures\n",
    ".agg(round(avg('temp_max'), 2).alias('avg_max_temp'),\n",
    "     round(avg('temp_min'), 2).alias('avg_min_temp'))\n",
    "    \n",
    "# Display the results.\n",
    ".show()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of rainy days in Q3 of 2015.\n",
      "+----------------------------------+\n",
      "|Q32015_pct_days_with_precipitation|\n",
      "+----------------------------------+\n",
      "|                            0.0217|\n",
      "+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What percentage of days were rainy in q3 of 2015?\n",
    "print(\"The percentage of rainy days in Q3 of 2015.\")\n",
    "(\n",
    "weather\n",
    "    \n",
    "# Filter 2015 temperature data\n",
    ".filter(year('date') == 2015)\n",
    "    \n",
    "# In Q3 of 2015\n",
    ".where(quarter('date') == 3)\n",
    "    \n",
    "# calculate the percentage of rain days\n",
    ".select(round(avg((col('weather') == 'rain').cast('int')), 4)\n",
    "        .alias('Q32015_pct_days_with_precipitation'))\n",
    "\n",
    "# Display the results\n",
    ".show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average percentage of days per year with non-zero precipitation.\n",
      "+----+-----------------+\n",
      "|year|avg_precipitation|\n",
      "+----+-----------------+\n",
      "|2015|            0.395|\n",
      "|2013|            0.416|\n",
      "|2014|            0.411|\n",
      "|2012|            0.484|\n",
      "+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each year, find what percentage of days it rained (had non-zero precipitation).\n",
    "print('The average percentage of days per year with non-zero precipitation.')\n",
    "(\n",
    "weather\n",
    "    \n",
    "# Select the years from the date column\n",
    ".select(year('date').alias('year'),\n",
    "\n",
    "# Create a Boolean series of non-zero precipitation days.\n",
    "(col('precipitation') != 0).cast('int').alias('precipitation'))\n",
    "    \n",
    "# Group by the year column\n",
    ".groupBy('year')\n",
    "    \n",
    "# Calculate the average number of days with percipitation for each year.\n",
    ".agg(round(mean('precipitation'), 3).alias('avg_precipitation'))\n",
    "    \n",
    "# Display the results.\n",
    ".show()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
